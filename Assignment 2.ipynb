{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Submit Assignment 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNsUdqwJyMG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HumoEAJmyX2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7YDcvL9ycAF",
        "colab_type": "code",
        "outputId": "36d33b33-9be9-4b92-9ddf-9a76743213fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_path = 'gdrive/My Drive/Colab_Models/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZfsHwzlwRjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWJovPp5zG6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNcj4iDJphih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "39174f5e-8dc9-429d-a651-7ba637eaca5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "6af4812c-3264-4896-b895-c8db2ebad052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70bce88d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "9d4645fd-e232-4652-e05b-25d619cbfd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "6a29d7c6-e676-4e1b-cf1b-769de1f8dc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqbfKOy4s77H",
        "colab_type": "text"
      },
      "source": [
        "# Architecting a deep learning model for MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik3OHONozzEQ",
        "colab_type": "text"
      },
      "source": [
        "# CODE 1:  \n",
        "Choosing an initial architecture for the model  \n",
        "\n",
        "> 28x28x1  | 3x3x1x8  \n",
        "26x26x8  | 3x3x8x16  \n",
        "24x24x16 | 3x3x16x24  \n",
        ">\n",
        "> 22x22x24 | MaxPooling  \n",
        "11x11x24 | 1x1x24x8  \n",
        ">\n",
        "> 11x11x8  | 3x3x8x16  \n",
        "9x9x16   | 3x3x16x32  \n",
        "7x7x32   | 1x1x32x10  \n",
        "7x7x10   | 7x7x10\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "8631f715-3705-40f8-e1d7-a2ec70c810d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu')) # 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 7\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "6ae57a1b-96d3-4c4b-c82b-8226726aa096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_65 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 7, 7, 24)          3480      \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 7, 7, 10)          250       \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,736\n",
            "Trainable params: 14,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeUyzMIitY9P",
        "colab_type": "text"
      },
      "source": [
        "- Defining the ModelCheckpoint callback to save the best model based on monitored value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LAabqCJ0Dwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('model_assignment_4.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vttuQ2ZctoIR",
        "colab_type": "text"
      },
      "source": [
        "- Training the model for 10 epochs with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "a458013f-6db4-4ed7-c411-175c5a530566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.2004 - acc: 0.9383 - val_loss: 0.0684 - val_acc: 0.9772\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0652 - acc: 0.9802 - val_loss: 0.0665 - val_acc: 0.9793\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0478 - val_acc: 0.9843\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0414 - acc: 0.9868 - val_loss: 0.0386 - val_acc: 0.9882\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0338 - acc: 0.9892 - val_loss: 0.0309 - val_acc: 0.9902\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0292 - acc: 0.9910 - val_loss: 0.0355 - val_acc: 0.9881\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 23s 376us/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0307 - val_acc: 0.9911\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0320 - val_acc: 0.9910\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 22s 375us/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0361 - val_acc: 0.9885\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 23s 375us/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0318 - val_acc: 0.9905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f387362f198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5eIE1ZvJjkq",
        "colab_type": "text"
      },
      "source": [
        "### Observation: \n",
        "We have reached a validation accuracy of **99.11% in the 7th epoch**. There is an observable gap between the training and validation accuracy in the 8th and 9th epoch.  \n",
        "\n",
        "The absolute difference is  \n",
        "0.0006  - 7th epoch  \n",
        "0.0016  - 8th epoch  \n",
        "0.0046  - 9th epoch\n",
        "\n",
        "### Inference: \n",
        "The model is overfitting after 7th epoch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZKqmUyjvDS6",
        "colab_type": "text"
      },
      "source": [
        "### EXPERIMENT: \n",
        "**Reduce the number of kernels** to prevent overfitting\n",
        "\n",
        "### Expectation: \n",
        "Increase in validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1EnSGA_JjRq",
        "colab_type": "code",
        "outputId": "36290eef-ba47-4d79-a3c4-b142044538c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) # 11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 7\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 00:57:39.556133 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "W0821 00:57:39.598793 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0821 00:57:39.606263 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "W0821 00:57:39.658420 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfEQLTu1rfST",
        "colab_type": "code",
        "outputId": "1fb4d5dd-dacb-4d6b-8e2a-66ef2dbc8f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint('model_assignment_4c.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0821 00:58:55.342418 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0821 00:58:55.366977 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 10)        170       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 12,902\n",
            "Trainable params: 12,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUSFNrZ5rwR7",
        "colab_type": "code",
        "outputId": "30f90424-1bae-4878-f546-dc9f92371bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0821 00:59:06.228381 140154775730048 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0821 00:59:06.313453 140154775730048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 18s 301us/step - loss: 0.1955 - acc: 0.9405 - val_loss: 0.0752 - val_acc: 0.9752\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0667 - acc: 0.9801 - val_loss: 0.0530 - val_acc: 0.9837\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0505 - acc: 0.9846 - val_loss: 0.0417 - val_acc: 0.9872\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0415 - acc: 0.9870 - val_loss: 0.0436 - val_acc: 0.9859\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0374 - val_acc: 0.9881\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0324 - acc: 0.9898 - val_loss: 0.0459 - val_acc: 0.9866\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0479 - val_acc: 0.9861\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.0352 - val_acc: 0.9899\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0232 - acc: 0.9924 - val_loss: 0.0447 - val_acc: 0.9872\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0208 - acc: 0.9934 - val_loss: 0.0424 - val_acc: 0.9875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7808ceb4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdboUAVNsi2l",
        "colab_type": "text"
      },
      "source": [
        "### Observation:\n",
        "**Validation accuracy did not improve** after reducing number of kernels. Highest validation accuracy in the above training was 98.99%\n",
        "\n",
        "### Inference:\n",
        "We need to try a different approach to reduce overfitting. Reducing the number of kernels has not worked. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E67_q8Rxd2n",
        "colab_type": "text"
      },
      "source": [
        "### EXPERIMENT:\n",
        "Reverting to previously chosen kernels and adding **batch normalization** after each Convolution2D layer to reduce overfitting  \n",
        "(Batch Normalization reduces internal covariate shift which in turn reduces overfitting)\n",
        "\n",
        "### Expectation:\n",
        "Validation accuracy should increase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNfH5dTCjJxH",
        "colab_type": "code",
        "outputId": "fd7fde9e-fe61-4432-bb2d-6475a9fccab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint('model_assignment_4g.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0821 09:48:21.981429 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "W0821 09:48:22.033600 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0821 09:48:22.045079 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0821 09:48:22.097823 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0821 09:48:22.099415 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0821 09:48:25.199074 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0821 09:48:25.668541 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "W0821 09:48:26.160958 140427764012928 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 24)          96        \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,160\n",
            "Trainable params: 14,948\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOqWbgB0ju-U",
        "colab_type": "code",
        "outputId": "ac2f7795-bb0d-41cf-ec4d-9f631ebeef1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0821 09:48:33.574261 140427764012928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 43s 713us/step - loss: 0.1367 - acc: 0.9575 - val_loss: 0.0598 - val_acc: 0.9816\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0488 - acc: 0.9847 - val_loss: 0.0419 - val_acc: 0.9869\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 40s 670us/step - loss: 0.0384 - acc: 0.9877 - val_loss: 0.0319 - val_acc: 0.9888\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 40s 659us/step - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0272 - val_acc: 0.9906\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 39s 642us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.0297 - val_acc: 0.9898\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 39s 654us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0274 - val_acc: 0.9917\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 39s 642us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0306 - val_acc: 0.9900\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0269 - val_acc: 0.9907\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 40s 667us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0301 - val_acc: 0.9903\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 40s 665us/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0340 - val_acc: 0.9910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb79549f5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "des2FGmlxVD4",
        "colab_type": "text"
      },
      "source": [
        "### Observation:\n",
        "1) Validation accuracy improved to **99.17% in the 6th epoch**. **(IMPROVEMENT 1)**\n",
        "\n",
        "2) The absolute difference between the training and validation accuracy is  \n",
        "0.0010  - 6th epoch  \n",
        "0.0035  - 7th epoch  \n",
        "0.0034  - 8th epoch  \n",
        "0.0044  - 9th epoch  \n",
        "0.0046  - 10th epoch  \n",
        "\n",
        "3) There is an increase decrease fluctuation in the validation accuracy and vice versa is the validation loss after 6th epoch\n",
        "\n",
        "### Inference:\n",
        "1) Batch Normalization has improved the model accuracy\n",
        "\n",
        "2) Model is overfitting after 6th epoch. \n",
        "\n",
        "3) The model is slightly diverging instead of converging (after 6th epoch). This could be due to learning rate being high\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUp_SS2_2Bfu",
        "colab_type": "text"
      },
      "source": [
        "# CODE 2:\n",
        "CODE 2 = CODE 1 + Batch Normalization + Reducing Learning rate\n",
        "\n",
        "### EXPERIMENT:\n",
        "Use a learning rate scheduler to gradually **decrease the learning rate** for each epoch\n",
        "\n",
        "### Expectation:\n",
        "Validation accuracy should increase and the divergent behavior should reduce\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxdiZOOs6Jh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jguMbspD6TWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbreW5rm6Lj3",
        "colab_type": "code",
        "outputId": "ab3a22f2-367d-409c-9bef-847295f88f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(root_path+'model_assignment_4e.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 24)          96        \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 7, 7, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,160\n",
            "Trainable params: 14,948\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVN6Z3bf6ZbO",
        "colab_type": "code",
        "outputId": "b4b42e86-5187-4f34-a102-45eb69008d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 39s 648us/step - loss: 0.1046 - acc: 0.9671 - val_loss: 0.0590 - val_acc: 0.9817\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0439 - acc: 0.9863 - val_loss: 0.0403 - val_acc: 0.9865\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0450 - val_acc: 0.9858\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0253 - acc: 0.9917 - val_loss: 0.0351 - val_acc: 0.9884\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0204 - acc: 0.9930 - val_loss: 0.0521 - val_acc: 0.9845\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 37s 624us/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0282 - val_acc: 0.9911\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 37s 622us/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0351 - val_acc: 0.9889\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 37s 619us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0368 - val_acc: 0.9892\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 37s 621us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0302 - val_acc: 0.9915\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 37s 618us/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0298 - val_acc: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18537224a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGrFaNw-3R2v",
        "colab_type": "text"
      },
      "source": [
        "### Observation:\n",
        "Model accuracy has increased to **99.26% (10th epoch)** after using a learning rate scheduler to decrease the learning rate. **(IMPROVEMENT 2)**\n",
        "\n",
        "### Inference:\n",
        "Since the highest validation accuracy was observed at the last epoch, we may see it increase further with increase in number of epochs (as learning rate is reduced with each epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abwxXGCuyQoo",
        "colab_type": "text"
      },
      "source": [
        "# CODE 3: \n",
        "CODE 3 = CODE 2 + Increase number of epochs to 15\n",
        "\n",
        "### EXPERIMENT:\n",
        "Increase **number of epochs to 15**\n",
        "\n",
        "### Expectation:\n",
        "Validation accuracy should increase "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybyKU4TH6yoc",
        "colab_type": "code",
        "outputId": "dd0458a0-c688-43d3-84ce-a0cc2d6df5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(root_path+'model_assignment_4e.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 7, 7, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 7, 7, 24)          96        \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 7, 7, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,160\n",
            "Trainable params: 14,948\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-8fYGp265Gp",
        "colab_type": "code",
        "outputId": "787e2710-d2d1-4444-dae8-30134423db40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 41s 686us/step - loss: 0.1144 - acc: 0.9639 - val_loss: 0.0600 - val_acc: 0.9812\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0451 - acc: 0.9857 - val_loss: 0.0347 - val_acc: 0.9889\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 38s 631us/step - loss: 0.0335 - acc: 0.9894 - val_loss: 0.0342 - val_acc: 0.9889\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 38s 631us/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.0313 - val_acc: 0.9902\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0204 - acc: 0.9936 - val_loss: 0.0264 - val_acc: 0.9908\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0295 - val_acc: 0.9912\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0246 - val_acc: 0.9927\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 38s 633us/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0341 - val_acc: 0.9905\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 38s 635us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0263 - val_acc: 0.9926\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 38s 634us/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0302 - val_acc: 0.9913\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0282 - val_acc: 0.9916\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0304 - val_acc: 0.9920\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 38s 631us/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0350 - val_acc: 0.9909\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 38s 629us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0296 - val_acc: 0.9919\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 38s 630us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0309 - val_acc: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1850ee5da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnhO5XCxWZEH",
        "colab_type": "text"
      },
      "source": [
        "### Observation:\n",
        "1) Model accuracy has increased to **99.35% (15th epoch)** after increasing number of epochs to 15. **(IMPROVEMENT 3)**\n",
        "\n",
        "2) Considerable difference between training and validation accuracy still exists\n",
        "\n",
        "### Inference:\n",
        "Model is still overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihSbejM61-yc",
        "colab_type": "text"
      },
      "source": [
        "# CODE 4: \n",
        "CODE 4 = CODE 3 + DropOut\n",
        "\n",
        "### EXPERIMENT:\n",
        "Adding a **DropOut** of 0.05 after each layer\n",
        "\n",
        "### Expectation:\n",
        "Validation accuracy should increase and overfitting should reduce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP10MED-iTkU",
        "colab_type": "code",
        "outputId": "98752859-b434-400f-b2cc-cf6af5d725d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1))) # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu')) # 11\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(10, 7))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(root_path+'model_assignment_4h.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 11, 11, 8)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 9, 9, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 24)          3480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 7, 7, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 7, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 10)          250       \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,160\n",
            "Trainable params: 14,948\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhtvvi5nsbKN",
        "colab_type": "code",
        "outputId": "547e5484-2dba-4a8b-f6e8-2d8e4679a65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 47s 791us/step - loss: 0.1270 - acc: 0.9597 - val_loss: 0.0457 - val_acc: 0.9840\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 43s 725us/step - loss: 0.0537 - acc: 0.9833 - val_loss: 0.0421 - val_acc: 0.9852\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 44s 732us/step - loss: 0.0395 - acc: 0.9875 - val_loss: 0.0295 - val_acc: 0.9904\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 44s 736us/step - loss: 0.0320 - acc: 0.9894 - val_loss: 0.0313 - val_acc: 0.9898\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 44s 734us/step - loss: 0.0287 - acc: 0.9908 - val_loss: 0.0231 - val_acc: 0.9924\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 45s 748us/step - loss: 0.0240 - acc: 0.9919 - val_loss: 0.0255 - val_acc: 0.9926\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.0220 - acc: 0.9927 - val_loss: 0.0214 - val_acc: 0.9929\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 44s 740us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9932\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 44s 741us/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0219 - val_acc: 0.9926\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 44s 737us/step - loss: 0.0158 - acc: 0.9952 - val_loss: 0.0245 - val_acc: 0.9927\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 44s 735us/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.0209 - val_acc: 0.9938\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 44s 732us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0184 - val_acc: 0.9948\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 45s 743us/step - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0190 - val_acc: 0.9941\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 45s 742us/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0221 - val_acc: 0.9936\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 44s 738us/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0240 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb748624588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSjPibzBaAIW",
        "colab_type": "text"
      },
      "source": [
        "### Observation:\n",
        "1) Model accuracy has increased to **99.48% (13th epoch)** after adding DropOut **(IMPROVEMENT 4)**\n",
        "\n",
        "2) Difference between training and validation accuracy is not as much as before\n",
        "\n",
        "### Inference:\n",
        "Overfitting has reduced\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLaQMEJmdu4m",
        "colab_type": "text"
      },
      "source": [
        "### Model accuracy of 99.48% achieved (using 15,160 params; within 15 epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd-SXqN3vlh_",
        "colab_type": "text"
      },
      "source": [
        "### Can we reach validation accuracy >=99.4% with <15k params\n",
        "\n",
        "Params of model above is slightly more than 15k. Let's see if we can bring it below 15k and still achieve validation accuracy of >=99.4%\n",
        "\n",
        "To reduce model params, we are  \n",
        "1)  Removing bias  \n",
        "2) Reducing number of kernels slightly (from 16 to 14 in 2nd and 5th Conv2D layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo1dpv8JvZ6E",
        "colab_type": "code",
        "outputId": "4c599d9f-7e61-4925-bca6-65f15b6be471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1), bias=False)) # 26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu', bias=False)) # 24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu', bias=False)) # 22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # 11\n",
        "model.add(Convolution2D(8, 1, 1, activation='relu', bias=False)) # 11\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu', bias=False)) # 9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu', bias=False)) # 7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.05))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu', bias=False)) #7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Convolution2D(10, 7, bias=False))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.003),\n",
        "             metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(root_path+'model_assignment_4i.h5', save_best_only=True,monitor='val_acc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., use_bias=False)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (1, 1), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 26, 26, 8)         72        \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 24, 24, 14)        1008      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 24, 24, 14)        56        \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 24, 24, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 22, 22, 24)        3024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 22, 22, 24)        96        \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 22, 22, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 11, 11, 8)         192       \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 11, 11, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 11, 11, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 9, 9, 14)          1008      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 9, 9, 14)          56        \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 9, 9, 14)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 7, 7, 24)          3024      \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 7, 7, 24)          96        \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 7, 7, 24)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 7, 7, 10)          240       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 1, 1, 10)          4900      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,876\n",
            "Trainable params: 13,672\n",
            "Non-trainable params: 204\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, 1, activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, 7, use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mNOL73Jv1Qz",
        "colab_type": "code",
        "outputId": "e0b4e04c-8309-432c-ab5b-6671bcd030c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1),checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 43s 718us/step - loss: 0.1268 - acc: 0.9609 - val_loss: 0.0609 - val_acc: 0.9817\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 41s 681us/step - loss: 0.0519 - acc: 0.9837 - val_loss: 0.0327 - val_acc: 0.9899\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 40s 675us/step - loss: 0.0430 - acc: 0.9867 - val_loss: 0.0318 - val_acc: 0.9891\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 40s 673us/step - loss: 0.0342 - acc: 0.9889 - val_loss: 0.0264 - val_acc: 0.9924\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 40s 664us/step - loss: 0.0290 - acc: 0.9901 - val_loss: 0.0256 - val_acc: 0.9919\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 39s 645us/step - loss: 0.0255 - acc: 0.9920 - val_loss: 0.0238 - val_acc: 0.9923\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 38s 637us/step - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0248 - val_acc: 0.9928\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 38s 634us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0225 - val_acc: 0.9927\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 40s 664us/step - loss: 0.0193 - acc: 0.9936 - val_loss: 0.0241 - val_acc: 0.9926\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.0161 - acc: 0.9944 - val_loss: 0.0254 - val_acc: 0.9924\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 37s 610us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0271 - val_acc: 0.9927\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 37s 621us/step - loss: 0.0140 - acc: 0.9950 - val_loss: 0.0244 - val_acc: 0.9928\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 39s 654us/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0250 - val_acc: 0.9929\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 39s 656us/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0227 - val_acc: 0.9938\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 40s 663us/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0228 - val_acc: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb7466d9358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIVmOfZ9dUPk",
        "colab_type": "text"
      },
      "source": [
        "### Model accuracy of 99.4% achieved (15th epoch; using 13,876 params)"
      ]
    }
  ]
}